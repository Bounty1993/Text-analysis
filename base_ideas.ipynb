{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras import models, layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 4, 2, 5, 6]\n",
      "[1, 7, 8, 9, 1, 10]\n",
      "[11, 12]\n",
      "[3, 13, 14, 15, 16]\n",
      "[3, 17, 18, 2, 19, 20, 21, 22, 1, 23, 24]\n",
      "Unique worlds: 24\n"
     ]
    }
   ],
   "source": [
    "samples = ['The cat is really beautiful.', \n",
    "           'The other side of the world',\n",
    "          'Hello Boy!',\n",
    "          'I hope you like me.',\n",
    "          'I think it is too late to find the correct way.']\n",
    "tokenizer = Tokenizer(num_words=1000)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "seq = tokenizer.texts_to_sequences(samples)\n",
    "for s in seq:\n",
    "    print(s)\n",
    "print(f'Unique worlds: {len(tokenizer.word_index)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  2,  5,  6,  0,  0,  0,  0,  0],\n",
       "       [ 1,  7,  8,  9,  1, 10,  0,  0,  0,  0],\n",
       "       [11, 12,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 13, 14, 15, 16,  0,  0,  0,  0,  0],\n",
       "       [17, 18,  2, 19, 20, 21, 22,  1, 23, 24]], dtype=int32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_seq = pad_sequences(seq, 10, padding='post')\n",
    "input_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  4,  2,  5,  6,  0,  0,  0,  0,  0],\n",
       "       [ 1,  7,  8,  9,  1, 10,  0,  0,  0,  0],\n",
       "       [11, 12,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 13, 14, 15, 16,  0,  0,  0,  0,  0],\n",
       "       [ 3, 17, 18,  2, 19, 20, 21, 22,  1, 23]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pad_sequences(seq, 10, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_feat = 10_000\n",
    "maxlen = 200\n",
    "(train_X, train_Y), (test_X, test_Y) = imdb.load_data(num_words=max_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 200)]             0         \n",
      "_________________________________________________________________\n",
      "embedding_5 (Embedding)      (None, 200, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 1601      \n",
      "=================================================================\n",
      "Total params: 81,601\n",
      "Trainable params: 81,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train_X = pad_sequences(train_X, maxlen=maxlen, padding='post')\n",
    "test_X = pad_sequences(test_X, maxlen=maxlen, padding='post')\n",
    "\n",
    "input_layer = layers.Input(shape=(maxlen))\n",
    "emb_layer = layers.Embedding(max_feat, 8)(input_layer)\n",
    "emb_layer = layers.Flatten()(emb_layer)\n",
    "output = layers.Dense(1, activation='sigmoid')(emb_layer)\n",
    "model = models.Model(input_layer, output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 30us/sample - loss: 1.0390 - acc: 0.8492\n",
      "Test Accuracy: 0.8492000102996826\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_X, train_Y, \n",
    "          epochs=10, \n",
    "          batch_size=32,\n",
    "          verbose=0,\n",
    "          validation_split=0.2)\n",
    "scores = model.evaluate(test_X, test_Y)\n",
    "print(f'Test Accuracy: {scores[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_train = os.path.join('datasets', 'imdb', 'train')\n",
    "data = []\n",
    "labels = []\n",
    "for cat in ['pos', 'neg']:\n",
    "    tar_dir = os.path.join(imdb_train, cat)\n",
    "    files = os.listdir(tar_dir)\n",
    "    for file in files:\n",
    "        if os.path.splitext(file)[1] == '.txt':\n",
    "            file_path = os.path.join(tar_dir, file)\n",
    "            with open(file_path) as f:\n",
    "                data.append(f.read())\n",
    "            if cat == 'pos':\n",
    "                labels.append(1)\n",
    "            else:\n",
    "                labels.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of review: 1\n",
      "\n",
      "I was amazed at the improvements made in an animated film. If you sit close to the screen, you will see the detail in the grass and surface structures. The detail, colors, and shading are at least an order of magnitude better than Toy Story. How they were able to pull off the shading, I will never know. I do hope that PIXAR will provide a documentary on how the film was produced so I can find out how all this was accomplished. Based on this film, I think animated films of the future will be judged on the basis of this film.\n"
     ]
    }
   ],
   "source": [
    "print('Type of review:', labels[0])\n",
    "print()\n",
    "print(data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words  400000\n"
     ]
    }
   ],
   "source": [
    "emb_index = {}\n",
    "emb_path = os.path.join('embeddings', 'glove.6B.100d.txt')\n",
    "with open(emb_path) as f:\n",
    "    for row in f:\n",
    "        line = row.split()\n",
    "        word = line[0]\n",
    "        vec = line[1:]\n",
    "        emb_index[word] = np.array(vec)\n",
    "print('Number of words ', len(emb_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
